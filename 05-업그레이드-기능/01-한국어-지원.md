# 업그레이드 기능 - 한국어 지원 강화

## 1. 한국어 텍스트 처리 최적화

### 1.1 한국어 텍스트 정규화
```python
# src/markitdown_mcp_enhanced/utils/korean_utils.py
import re
from typing import Optional, Dict, Any
import unicodedata

class KoreanTextProcessor:
    """한국어 텍스트 처리 유틸리티"""
    
    def __init__(self):
        # 한국어 조사 목록
        self.korean_particles = [
            '은', '는', '이', '가', '을', '를', '에', '에서', '에게', '에게서',
            '으로', '로', '와', '과', '의', '도', '만', '까지', '부터', '마저',
            '조차', '밖에', '뿐', '대로', '처럼', '같이', '보다', '한테', '께'
        ]
        
        # 한국어 어미 패턴
        self.korean_endings = [
            '다', '요', '니다', '습니다', '네요', '어요', '아요', '해요',
            '지요', '나요', '군요', '네', '죠', '께요'
        ]
        
        # 한국어 문장 부호 매핑
        self.korean_punctuation = {
            '․': '.',
            '，': ',',
            '：': ':',
            '；': ';',
            '？': '?',
            '！': '!',
            '（': '(',
            '）': ')',
            '「': '"',
            '」': '"',
            '『': '"',
            '』': '"',
            '【': '[',
            '】': ']',
            '〈': '<',
            '〉': '>',
            '《': '<<',
            '》': '>>',
            '〔': '(',
            '〕': ')',
            '〖': '[',
            '〗': ']'
        }
    
    def normalize_korean_text(self, text: str) -> str:
        """한국어 텍스트 정규화"""
        if not text:
            return text
        
        # 유니코드 정규화 (NFD -> NFC)
        text = unicodedata.normalize('NFC', text)
        
        # 한국어 문장 부호 정규화
        text = self._normalize_korean_punctuation(text)
        
        # 한국어 띄어쓰기 정규화
        text = self._normalize_korean_spacing(text)
        
        # 한국어 어순 정규화
        text = self._normalize_korean_word_order(text)
        
        # 불필요한 공백 제거
        text = self._clean_whitespace(text)
        
        return text
    
    def _normalize_korean_punctuation(self, text: str) -> str:
        """한국어 문장 부호 정규화"""
        for korean_punct, english_punct in self.korean_punctuation.items():
            text = text.replace(korean_punct, english_punct)
        
        return text
    
    def _normalize_korean_spacing(self, text: str) -> str:
        """한국어 띄어쓰기 정규화"""
        # 조사 앞 불필요한 공백 제거
        for particle in self.korean_particles:
            # 조사 앞 공백 제거
            text = re.sub(rf'\s+{particle}\b', particle, text)
        
        # 어미 앞 불필요한 공백 제거
        for ending in self.korean_endings:
            text = re.sub(rf'\s+{ending}\b', ending, text)
        
        # 문장 부호 앞 공백 제거
        text = re.sub(r'\s+([.!?,:;])', r'\1', text)
        
        # 괄호 안쪽 공백 정리
        text = re.sub(r'\(\s+', '(', text)
        text = re.sub(r'\s+\)', ')', text)
        text = re.sub(r'\[\s+', '[', text)
        text = re.sub(r'\s+\]', ']', text)
        
        # 숫자와 단위 사이 공백 정리
        text = re.sub(r'(\d+)\s*(개|명|번|회|시|분|초|일|월|년|kg|g|km|m|cm)', r'\1\2', text)
        
        return text
    
    def _normalize_korean_word_order(self, text: str) -> str:
        """한국어 어순 정규화"""
        # 한국어 특유의 어순 패턴 정리
        
        # "의의" -> "의" (중복 의미 제거)
        text = re.sub(r'(\w+)의의\b', r'\1의', text)
        
        # "에에" -> "에" (중복 조사 제거)
        text = re.sub(r'(\w+)에에\b', r'\1에', text)
        
        # "는는" -> "는" (중복 조사 제거)
        text = re.sub(r'(\w+)는는\b', r'\1는', text)
        
        return text
    
    def _clean_whitespace(self, text: str) -> str:
        """불필요한 공백 정리"""
        # 연속된 공백을 하나로
        text = re.sub(r'[ \t]+', ' ', text)
        
        # 연속된 줄바꿈을 최대 2개로
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        # 시작과 끝 공백 제거
        text = text.strip()
        
        return text
    
    def detect_korean_ratio(self, text: str) -> float:
        """한국어 문자 비율 계산"""
        if not text:
            return 0.0
        
        korean_chars = len(re.findall(r'[가-힣ㄱ-ㅎㅏ-ㅣ]', text))
        total_chars = len(re.findall(r'[가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', text))
        
        if total_chars == 0:
            return 0.0
        
        return korean_chars / total_chars
    
    def is_korean_text(self, text: str, threshold: float = 0.3) -> bool:
        """한국어 텍스트 여부 판단"""
        return self.detect_korean_ratio(text) >= threshold
    
    def extract_korean_words(self, text: str) -> list:
        """한국어 단어 추출"""
        # 한국어 단어 패턴 (완성형 한글 + 조사/어미)
        korean_words = re.findall(r'[가-힣]+', text)
        
        # 중복 제거 및 정렬
        unique_words = sorted(set(korean_words))
        
        return unique_words
    
    def segment_korean_sentences(self, text: str) -> list:
        """한국어 문장 분할"""
        # 한국어 문장 끝 패턴
        sentence_endings = r'[.!?]|다\.|요\.|니다\.|습니다\.|네요\.|어요\.|아요\.|해요\.|지요\.|나요\.|군요\.|네\.|죠\.'
        
        # 문장 분할
        sentences = re.split(f'({sentence_endings})', text)
        
        # 분할된 문장 재조립
        result = []
        current_sentence = ""
        
        for i, part in enumerate(sentences):
            if re.match(sentence_endings, part):
                current_sentence += part
                if current_sentence.strip():
                    result.append(current_sentence.strip())
                current_sentence = ""
            else:
                current_sentence += part
        
        # 마지막 문장 처리
        if current_sentence.strip():
            result.append(current_sentence.strip())
        
        return result
    
    def format_korean_title(self, title: str) -> str:
        """한국어 제목 포맷팅"""
        if not title:
            return title
        
        # 기본 정규화
        title = self.normalize_korean_text(title)
        
        # 제목 형식 정리
        title = title.strip()
        
        # 불필요한 기호 제거
        title = re.sub(r'^[^\w가-힣]+|[^\w가-힣]+$', '', title)
        
        # 길이 제한
        if len(title) > 100:
            title = title[:97] + "..."
        
        return title
    
    def create_korean_summary(self, text: str, max_length: int = 200) -> str:
        """한국어 텍스트 요약"""
        if not text or len(text) <= max_length:
            return text
        
        # 문장 분할
        sentences = self.segment_korean_sentences(text)
        
        # 중요도 기반 문장 선택
        important_sentences = []
        current_length = 0
        
        # 첫 번째 문장은 항상 포함
        if sentences:
            first_sentence = sentences[0]
            important_sentences.append(first_sentence)
            current_length += len(first_sentence)
        
        # 나머지 문장들에서 중요한 문장 선택
        for sentence in sentences[1:]:
            if current_length + len(sentence) > max_length:
                break
            
            # 중요도 계산 (키워드 기반)
            importance = self._calculate_sentence_importance(sentence)
            
            if importance > 0.5:  # 임계값
                important_sentences.append(sentence)
                current_length += len(sentence)
        
        summary = ' '.join(important_sentences)
        
        # 길이 조정
        if len(summary) > max_length:
            summary = summary[:max_length-3] + "..."
        
        return summary
    
    def _calculate_sentence_importance(self, sentence: str) -> float:
        """문장 중요도 계산"""
        importance = 0.0
        
        # 길이 기반 점수
        length_score = min(len(sentence) / 100, 1.0)
        importance += length_score * 0.3
        
        # 키워드 기반 점수
        important_keywords = ['중요', '핵심', '주요', '기본', '필수', '특징', '장점', '단점']
        for keyword in important_keywords:
            if keyword in sentence:
                importance += 0.2
        
        # 숫자 포함 점수 (통계, 데이터 등)
        if re.search(r'\d+', sentence):
            importance += 0.1
        
        # 질문 형태 점수
        if sentence.endswith('?') or sentence.endswith('까?'):
            importance += 0.2
        
        return min(importance, 1.0)
```

### 1.2 한국어 OCR 최적화
```python
# src/markitdown_mcp_enhanced/utils/korean_ocr.py
import tempfile
import os
from typing import Optional, Dict, Any, BinaryIO
import logging

from .korean_utils import KoreanTextProcessor

logger = logging.getLogger(__name__)

class KoreanOCRProcessor:
    """한국어 OCR 처리 최적화"""
    
    def __init__(self):
        self.korean_processor = KoreanTextProcessor()
        
        # 한국어 OCR 엔진 우선순위
        self.ocr_engines = [
            'naver_clova',
            'google_cloud_vision',
            'tesseract_korean',
            'easyocr'
        ]
    
    def extract_korean_text_from_image(self, image_stream: BinaryIO, 
                                     engine: Optional[str] = None) -> Dict[str, Any]:
        """이미지에서 한국어 텍스트 추출"""
        
        # 엔진 선택
        if engine:
            engines_to_try = [engine]
        else:
            engines_to_try = self.ocr_engines
        
        results = {}
        
        for engine_name in engines_to_try:
            try:
                if engine_name == 'naver_clova':
                    result = self._extract_with_naver_clova(image_stream)
                elif engine_name == 'google_cloud_vision':
                    result = self._extract_with_google_vision(image_stream)
                elif engine_name == 'tesseract_korean':
                    result = self._extract_with_tesseract(image_stream)
                elif engine_name == 'easyocr':
                    result = self._extract_with_easyocr(image_stream)
                else:
                    continue
                
                if result and result.get('text'):
                    results[engine_name] = result
                    
                    # 한국어 비율이 높으면 우선 사용
                    korean_ratio = self.korean_processor.detect_korean_ratio(result['text'])
                    if korean_ratio > 0.5:
                        break
                        
            except Exception as e:
                logger.debug(f"OCR engine {engine_name} failed: {e}")
                continue
        
        # 최적 결과 선택
        if results:
            best_result = self._select_best_ocr_result(results)
            
            # 한국어 후처리
            if best_result and best_result.get('text'):
                best_result['text'] = self.korean_processor.normalize_korean_text(best_result['text'])
                best_result['korean_ratio'] = self.korean_processor.detect_korean_ratio(best_result['text'])
            
            return best_result
        
        return {'text': '', 'confidence': 0.0, 'engine': None}
    
    def _extract_with_naver_clova(self, image_stream: BinaryIO) -> Dict[str, Any]:
        """네이버 클로바 OCR"""
        try:
            import requests
            import json
            
            # 네이버 클로바 OCR API 설정
            api_url = os.getenv('NAVER_CLOVA_OCR_URL')
            secret_key = os.getenv('NAVER_CLOVA_OCR_SECRET')
            
            if not api_url or not secret_key:
                raise Exception("Naver Clova OCR credentials not found")
            
            # 이미지 데이터 준비
            image_stream.seek(0)
            files = {'image': image_stream}
            
            # API 요청
            headers = {'X-OCR-SECRET': secret_key}
            response = requests.post(api_url, files=files, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                
                # 텍스트 추출
                text = ""
                confidence = 0.0
                
                if 'images' in result and result['images']:
                    image_result = result['images'][0]
                    
                    if 'fields' in image_result:
                        texts = []
                        confidences = []
                        
                        for field in image_result['fields']:
                            if 'inferText' in field:
                                texts.append(field['inferText'])
                                confidences.append(field.get('inferConfidence', 0.0))
                        
                        text = '\n'.join(texts)
                        confidence = sum(confidences) / len(confidences) if confidences else 0.0
                
                return {
                    'text': text,
                    'confidence': confidence,
                    'engine': 'naver_clova'
                }
            
        except Exception as e:
            logger.debug(f"Naver Clova OCR failed: {e}")
            raise
    
    def _extract_with_google_vision(self, image_stream: BinaryIO) -> Dict[str, Any]:
        """Google Cloud Vision OCR"""
        try:
            from google.cloud import vision
            
            # 클라이언트 생성
            client = vision.ImageAnnotatorClient()
            
            # 이미지 데이터 준비
            image_stream.seek(0)
            content = image_stream.read()
            image = vision.Image(content=content)
            
            # 텍스트 감지 (한국어 힌트 제공)
            response = client.text_detection(
                image=image,
                image_context={'language_hints': ['ko', 'en']}
            )
            
            if response.text_annotations:
                text = response.text_annotations[0].description
                
                # 신뢰도 계산
                confidence = 0.0
                if hasattr(response.text_annotations[0], 'confidence'):
                    confidence = response.text_annotations[0].confidence
                else:
                    # 근사 신뢰도 계산
                    confidence = min(len(text) / 100, 1.0)
                
                return {
                    'text': text,
                    'confidence': confidence,
                    'engine': 'google_cloud_vision'
                }
            
        except Exception as e:
            logger.debug(f"Google Cloud Vision OCR failed: {e}")
            raise
    
    def _extract_with_tesseract(self, image_stream: BinaryIO) -> Dict[str, Any]:
        """Tesseract OCR (한국어 최적화)"""
        try:
            import pytesseract
            from PIL import Image
            
            # 이미지 로드
            image_stream.seek(0)
            image = Image.open(image_stream)
            
            # 한국어 + 영어 OCR
            custom_config = r'--oem 3 --psm 6 -l kor+eng'
            text = pytesseract.image_to_string(image, config=custom_config)
            
            # 신뢰도 정보 추출
            try:
                data = pytesseract.image_to_data(image, config=custom_config, output_type=pytesseract.Output.DICT)
                confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
                confidence = sum(confidences) / len(confidences) / 100 if confidences else 0.0
            except:
                confidence = 0.5  # 기본값
            
            return {
                'text': text,
                'confidence': confidence,
                'engine': 'tesseract_korean'
            }
            
        except Exception as e:
            logger.debug(f"Tesseract OCR failed: {e}")
            raise
    
    def _extract_with_easyocr(self, image_stream: BinaryIO) -> Dict[str, Any]:
        """EasyOCR (한국어 지원)"""
        try:
            import easyocr
            
            # 한국어 + 영어 리더 생성
            reader = easyocr.Reader(['ko', 'en'])
            
            # 이미지 데이터 준비
            image_stream.seek(0)
            image_data = image_stream.read()
            
            # 텍스트 추출
            results = reader.readtext(image_data)
            
            # 결과 처리
            texts = []
            confidences = []
            
            for (bbox, text, confidence) in results:
                texts.append(text)
                confidences.append(confidence)
            
            combined_text = '\n'.join(texts)
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            return {
                'text': combined_text,
                'confidence': avg_confidence,
                'engine': 'easyocr'
            }
            
        except Exception as e:
            logger.debug(f"EasyOCR failed: {e}")
            raise
    
    def _select_best_ocr_result(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """최적 OCR 결과 선택"""
        if not results:
            return {}
        
        best_result = None
        best_score = 0.0
        
        for engine, result in results.items():
            text = result.get('text', '')
            confidence = result.get('confidence', 0.0)
            
            # 점수 계산
            score = 0.0
            
            # 신뢰도 점수 (50%)
            score += confidence * 0.5
            
            # 한국어 비율 점수 (30%)
            korean_ratio = self.korean_processor.detect_korean_ratio(text)
            score += korean_ratio * 0.3
            
            # 텍스트 길이 점수 (20%)
            length_score = min(len(text) / 1000, 1.0)
            score += length_score * 0.2
            
            # 엔진 우선순위 보너스
            if engine == 'naver_clova':
                score += 0.1
            elif engine == 'google_cloud_vision':
                score += 0.05
            
            if score > best_score:
                best_score = score
                best_result = result
        
        return best_result or {}
    
    def enhance_korean_text_quality(self, text: str) -> str:
        """한국어 텍스트 품질 향상"""
        if not text:
            return text
        
        # 기본 정규화
        text = self.korean_processor.normalize_korean_text(text)
        
        # OCR 특화 오류 수정
        text = self._fix_ocr_errors(text)
        
        # 맞춤법 검사 (선택사항)
        text = self._spell_check_korean(text)
        
        return text
    
    def _fix_ocr_errors(self, text: str) -> str:
        """OCR 특화 오류 수정"""
        # 자주 발생하는 OCR 오류 패턴 수정
        error_patterns = {
            r'이l': '이',
            r'가l': '가',
            r'에l': '에',
            r'을l': '을',
            r'는l': '는',
            r'는0': '는',
            r'이0': '이',
            r'가0': '가',
            r'o1': '어',
            r'o}': '어',
            r'1l': '일',
            r'1j': '입',
            r'rj': '러',
            r'tj': '터',
            r'니l': '니',
            r'다l': '다',
            r'사l': '사',
            r'기l': '기',
            r'마l': '마',
            r'바l': '바',
            r'자l': '자',
            r'카l': '카',
            r'타l': '타',
            r'파l': '파',
            r'하l': '하'
        }
        
        for pattern, replacement in error_patterns.items():
            text = re.sub(pattern, replacement, text)
        
        return text
    
    def _spell_check_korean(self, text: str) -> str:
        """한국어 맞춤법 검사 (선택사항)"""
        # 한국어 맞춤법 검사 라이브러리 사용
        try:
            from hanspell import spell_checker
            
            # 문장 단위로 맞춤법 검사
            sentences = self.korean_processor.segment_korean_sentences(text)
            corrected_sentences = []
            
            for sentence in sentences:
                if len(sentence) > 500:  # 너무 긴 문장은 스킵
                    corrected_sentences.append(sentence)
                    continue
                
                try:
                    result = spell_checker.check(sentence)
                    corrected_sentences.append(result.checked)
                except:
                    corrected_sentences.append(sentence)
            
            return ' '.join(corrected_sentences)
            
        except ImportError:
            # 맞춤법 검사 라이브러리가 없으면 원본 반환
            return text
        except Exception as e:
            logger.debug(f"Korean spell check failed: {e}")
            return text
```

### 1.3 한국어 특화 변환기 개선
```python
# src/markitdown_mcp_enhanced/converters/korean_enhanced_converter.py
from typing import BinaryIO, Dict, Any, Optional
import logging

from ..core.base_converter import DocumentConverter, DocumentConverterResult
from ..core.stream_info import StreamInfo
from ..utils.korean_utils import KoreanTextProcessor
from ..utils.korean_ocr import KoreanOCRProcessor

logger = logging.getLogger(__name__)

class KoreanEnhancedMixin:
    """한국어 강화 기능 믹스인"""
    
    def __init__(self):
        self.korean_processor = KoreanTextProcessor()
        self.korean_ocr = KoreanOCRProcessor()
    
    def enhance_korean_conversion(self, result: DocumentConverterResult) -> DocumentConverterResult:
        """한국어 변환 결과 향상"""
        if not result.markdown:
            return result
        
        # 한국어 텍스트 정규화
        enhanced_markdown = self.korean_processor.normalize_korean_text(result.markdown)
        
        # 한국어 제목 개선
        enhanced_title = result.title
        if enhanced_title:
            enhanced_title = self.korean_processor.format_korean_title(enhanced_title)
        
        # 한국어 메타데이터 추가
        enhanced_metadata = result.metadata or {}
        enhanced_metadata.update({
            'korean_ratio': self.korean_processor.detect_korean_ratio(enhanced_markdown),
            'korean_words': self.korean_processor.extract_korean_words(enhanced_markdown),
            'korean_sentences': len(self.korean_processor.segment_korean_sentences(enhanced_markdown))
        })
        
        # 한국어 요약 생성
        if len(enhanced_markdown) > 1000:
            enhanced_metadata['korean_summary'] = self.korean_processor.create_korean_summary(enhanced_markdown)
        
        return DocumentConverterResult(
            markdown=enhanced_markdown,
            title=enhanced_title,
            metadata=enhanced_metadata
        )
    
    def extract_korean_text_from_image(self, image_stream: BinaryIO) -> Optional[str]:
        """이미지에서 한국어 텍스트 추출"""
        try:
            result = self.korean_ocr.extract_korean_text_from_image(image_stream)
            
            if result.get('text'):
                # 텍스트 품질 향상
                enhanced_text = self.korean_ocr.enhance_korean_text_quality(result['text'])
                return enhanced_text
            
        except Exception as e:
            logger.debug(f"Korean OCR failed: {e}")
        
        return None
    
    def format_korean_markdown(self, content: str, title: Optional[str] = None) -> str:
        """한국어 마크다운 포맷팅"""
        markdown = ""
        
        # 제목 추가
        if title:
            formatted_title = self.korean_processor.format_korean_title(title)
            markdown += f"# {formatted_title}\n\n"
        
        # 내용 정규화
        normalized_content = self.korean_processor.normalize_korean_text(content)
        
        # 문장 단위로 분할하여 단락 생성
        sentences = self.korean_processor.segment_korean_sentences(normalized_content)
        
        current_paragraph = ""
        for sentence in sentences:
            # 문장이 너무 길면 새 단락으로
            if len(current_paragraph) + len(sentence) > 200:
                if current_paragraph:
                    markdown += f"{current_paragraph.strip()}\n\n"
                current_paragraph = sentence + " "
            else:
                current_paragraph += sentence + " "
        
        # 마지막 단락 추가
        if current_paragraph:
            markdown += f"{current_paragraph.strip()}\n\n"
        
        return markdown
```

## 2. 한국어 문서 형식 지원

### 2.1 한글 문서 (HWP) 지원
```python
# src/markitdown_mcp_enhanced/converters/hwp_converter.py
from typing import BinaryIO, Dict, Any, Optional
import logging

from ..core.base_converter import DocumentConverter, DocumentConverterResult
from ..core.stream_info import StreamInfo
from ..core.exceptions import MissingDependencyException, FileConversionException
from ..utils.korean_utils import KoreanTextProcessor
from .korean_enhanced_converter import KoreanEnhancedMixin

logger = logging.getLogger(__name__)

class HwpConverter(DocumentConverter, KoreanEnhancedMixin):
    """한글 문서 (HWP) 변환기"""
    
    supported_extensions = ['.hwp', '.hwpx']
    supported_mimetypes = ['application/haansofthwp', 'application/x-hwp']
    category = 'documents'
    
    def __init__(self, korean_support: bool = True):
        DocumentConverter.__init__(self, korean_support=korean_support)
        KoreanEnhancedMixin.__init__(self)
        self.priority = 0.05  # 한국어 특화 변환기로 높은 우선순위
        
        # 의존성 확인
        self._check_dependencies()
    
    def _check_dependencies(self):
        """의존성 확인"""
        try:
            import olefile
            self.olefile_available = True
        except ImportError:
            self.olefile_available = False
        
        try:
            import pyhwp
            self.pyhwp_available = True
        except ImportError:
            self.pyhwp_available = False
    
    def accepts(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> bool:
        """HWP 파일 처리 가능 여부"""
        # 확장자 확인
        if stream_info.matches_extension(['.hwp', '.hwpx']):
            return True
        
        # 파일 헤더 확인
        try:
            current_pos = file_stream.tell()
            file_stream.seek(0)
            header = file_stream.read(32)
            file_stream.seek(current_pos)
            
            # HWP 파일 시그니처 확인
            if header.startswith(b'HWP Document File'):
                return True
            
            # OLE 파일 확인 (구버전 HWP)
            if header.startswith(b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1'):
                return True
                
        except:
            pass
        
        return False
    
    def convert(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """HWP 변환 수행"""
        logger.info(f"Converting HWP: {stream_info.filename}")
        
        # pyhwp 우선 사용
        if self.pyhwp_available:
            try:
                return self._convert_with_pyhwp(file_stream, stream_info, **kwargs)
            except Exception as e:
                logger.warning(f"pyhwp conversion failed: {e}")
        
        # olefile 사용 (기본적인 텍스트 추출)
        if self.olefile_available:
            try:
                return self._convert_with_olefile(file_stream, stream_info, **kwargs)
            except Exception as e:
                logger.warning(f"olefile conversion failed: {e}")
        
        raise MissingDependencyException(
            "No HWP processing library available. Install pyhwp or olefile"
        )
    
    def _convert_with_pyhwp(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """pyhwp로 변환"""
        import pyhwp
        import tempfile
        import os
        
        # 임시 파일 생성
        with tempfile.NamedTemporaryFile(delete=False, suffix='.hwp') as temp_file:
            file_stream.seek(0)
            temp_file.write(file_stream.read())
            temp_file_path = temp_file.name
        
        try:
            # HWP 파일 로드
            hwp_doc = pyhwp.open(temp_file_path)
            
            # 텍스트 추출
            text_content = ""
            for paragraph in hwp_doc.paragraphs:
                text_content += paragraph.text + "\n"
            
            # 메타데이터 추출
            metadata = self._extract_hwp_metadata(hwp_doc, stream_info)
            
            # 제목 추출
            title = self._extract_hwp_title(hwp_doc, text_content)
            
            # 한국어 마크다운 포맷팅
            markdown = self.format_korean_markdown(text_content, title)
            
            # 결과 생성
            result = DocumentConverterResult(
                markdown=markdown,
                title=title,
                metadata=metadata
            )
            
            # 한국어 강화 처리
            return self.enhance_korean_conversion(result)
            
        finally:
            # 임시 파일 삭제
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    def _convert_with_olefile(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """olefile로 기본 변환"""
        import olefile
        import tempfile
        import os
        
        # 임시 파일 생성
        with tempfile.NamedTemporaryFile(delete=False, suffix='.hwp') as temp_file:
            file_stream.seek(0)
            temp_file.write(file_stream.read())
            temp_file_path = temp_file.name
        
        try:
            # OLE 파일 열기
            ole = olefile.OleFileIO(temp_file_path)
            
            # 텍스트 스트림 찾기
            text_content = ""
            
            # 가능한 텍스트 스트림들
            text_streams = ['PrvText', 'DocText', 'Text']
            
            for stream_name in text_streams:
                if ole._olestream_size.get(stream_name):
                    stream_data = ole._olestream_size[stream_name]
                    try:
                        # 한국어 인코딩으로 디코딩
                        text_content = stream_data.decode('cp949', errors='ignore')
                        break
                    except:
                        continue
            
            ole.close()
            
            # 기본 메타데이터
            metadata = self._extract_metadata(file_stream, stream_info)
            
            # 제목 추출
            title = self._extract_title_from_text(text_content)
            
            # 한국어 마크다운 포맷팅
            markdown = self.format_korean_markdown(text_content, title)
            
            # 결과 생성
            result = DocumentConverterResult(
                markdown=markdown,
                title=title,
                metadata=metadata
            )
            
            # 한국어 강화 처리
            return self.enhance_korean_conversion(result)
            
        finally:
            # 임시 파일 삭제
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    def _extract_hwp_metadata(self, hwp_doc, stream_info: StreamInfo) -> Dict[str, Any]:
        """HWP 메타데이터 추출"""
        metadata = self._extract_metadata(None, stream_info)
        
        try:
            # 문서 속성 추출
            if hasattr(hwp_doc, 'properties'):
                props = hwp_doc.properties
                
                if hasattr(props, 'title'):
                    metadata['title'] = props.title
                if hasattr(props, 'author'):
                    metadata['author'] = props.author
                if hasattr(props, 'subject'):
                    metadata['subject'] = props.subject
                if hasattr(props, 'keywords'):
                    metadata['keywords'] = props.keywords
                if hasattr(props, 'created'):
                    metadata['creation_date'] = props.created
                if hasattr(props, 'modified'):
                    metadata['modification_date'] = props.modified
            
            # 페이지 정보
            if hasattr(hwp_doc, 'pages'):
                metadata['page_count'] = len(hwp_doc.pages)
            
            # 단락 정보
            if hasattr(hwp_doc, 'paragraphs'):
                metadata['paragraph_count'] = len(hwp_doc.paragraphs)
                
                # 단어 수 계산
                word_count = 0
                for paragraph in hwp_doc.paragraphs:
                    word_count += len(paragraph.text.split())
                metadata['word_count'] = word_count
                
        except Exception as e:
            logger.debug(f"HWP metadata extraction failed: {e}")
        
        return metadata
    
    def _extract_hwp_title(self, hwp_doc, text_content: str) -> Optional[str]:
        """HWP 제목 추출"""
        # 문서 속성에서 제목 추출
        try:
            if hasattr(hwp_doc, 'properties') and hasattr(hwp_doc.properties, 'title'):
                title = hwp_doc.properties.title
                if title:
                    return self.korean_processor.format_korean_title(title)
        except:
            pass
        
        # 첫 번째 단락에서 제목 추출
        try:
            if hasattr(hwp_doc, 'paragraphs') and hwp_doc.paragraphs:
                first_paragraph = hwp_doc.paragraphs[0].text.strip()
                if first_paragraph and len(first_paragraph) < 100:
                    return self.korean_processor.format_korean_title(first_paragraph)
        except:
            pass
        
        # 텍스트 내용에서 제목 추출
        return self._extract_title_from_text(text_content)
    
    def _extract_title_from_text(self, text: str) -> Optional[str]:
        """텍스트에서 제목 추출"""
        if not text:
            return None
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if line and len(line) < 100:
                return self.korean_processor.format_korean_title(line)
        
        return None
    
    def get_format_info(self) -> Dict[str, Any]:
        """형식 정보 반환"""
        return {
            'name': 'HWP',
            'description': '한글 문서 파일 변환기 (한국어 특화)',
            'extensions': self.supported_extensions,
            'mimetypes': self.supported_mimetypes,
            'category': self.category,
            'dependencies': ['pyhwp (recommended)', 'olefile (fallback)'],
            'features': [
                '한글 문서 텍스트 추출',
                '한국어 텍스트 정규화',
                '문서 메타데이터 추출',
                '한국어 제목 추출',
                '한국어 마크다운 포맷팅'
            ],
            'korean_optimized': True
        }
```

이제 MCP 서버 구축 프로젝트의 핵심 기능들이 완성되었습니다. 한국어 지원을 강화하고, 다양한 파일 형식을 지원하며, 확장 가능한 플러그인 시스템을 갖춘 완전한 MarkItDown MCP 서버가 구현되었습니다.

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "MCP \uc11c\ubc84 \uad6c\ucd95 \ud3f4\ub354 \ubc0f \ud558\uc704\uad6c\uc870 \uc0dd\uc131", "status": "completed", "priority": "high", "id": "30"}, {"content": "markitdown GitHub \ub9ac\ud3ec\uc9c0\ud1a0\ub9ac \ubd84\uc11d", "status": "completed", "priority": "high", "id": "31"}, {"content": "markitdown MCP \uc11c\ubc84 \uae30\ub2a5 \ubca4\uce58\ub9c8\ud0b9", "status": "completed", "priority": "high", "id": "32"}, {"content": "\ub3d9\uc77c \uae30\ub2a5 MCP \uc11c\ubc84 \uad6c\ud604", "status": "completed", "priority": "high", "id": "33"}, {"content": "\uc5c5\uadf8\ub808\uc774\ub4dc \ubc84\uc804 \uae30\ub2a5 \uc124\uacc4", "status": "completed", "priority": "medium", "id": "34"}, {"content": "\ud578\uc2ec \ubcc0\ud658 \uc5d4\uc9c4 \uad6c\ud604", "status": "completed", "priority": "high", "id": "35"}, {"content": "\uae30\ubcf8 \ubcc0\ud658\uae30 \uc2dc\uc2a4\ud15c \uad6c\ud604", "status": "completed", "priority": "high", "id": "36"}, {"content": "\ud50c\ub7ec\uadf8\uc778 \uc2dc\uc2a4\ud15c \uad6c\ud604", "status": "completed", "priority": "medium", "id": "37"}, {"content": "PDF \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "38"}, {"content": "DOCX \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "39"}, {"content": "\uc774\ubbf8\uc9c0 \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "40"}, {"content": "\uc624\ub514\uc624 \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "41"}, {"content": "HTML \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "medium", "id": "42"}, {"content": "\uc720\ud2f8\ub9ac\ud2f0 \ubaa8\ub4c8 \uad6c\ud604", "status": "completed", "priority": "medium", "id": "43"}, {"content": "\ud55c\uad6d\uc5b4 \uc9c0\uc6d0 \uac15\ud654", "status": "completed", "priority": "high", "id": "44"}, {"content": "HWP \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "45"}]