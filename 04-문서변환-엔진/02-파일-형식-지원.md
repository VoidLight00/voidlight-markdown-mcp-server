# 파일 형식 지원 구현

## 1. 유틸리티 모듈 구현

### 1.1 파일 타입 감지기
```python
# src/markitdown_mcp_enhanced/utils/file_detector.py
import io
import magic
from typing import Optional, BinaryIO, List
from pathlib import Path

from ..core.stream_info import StreamInfo
from ..config.logging_config import setup_logging

logger = setup_logging()

class FileTypeDetector:
    """파일 타입 감지기"""
    
    def __init__(self):
        try:
            # python-magic 초기화
            self.magic = magic.Magic(mime=True)
            self.magic_available = True
        except Exception as e:
            logger.warning(f"python-magic not available: {e}")
            self.magic_available = False
        
        # 확장자-MIME 타입 매핑
        self.extension_mapping = {
            '.pdf': 'application/pdf',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            '.ppt': 'application/vnd.ms-powerpoint',
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.xls': 'application/vnd.ms-excel',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.tiff': 'image/tiff',
            '.webp': 'image/webp',
            '.mp3': 'audio/mpeg',
            '.wav': 'audio/wav',
            '.m4a': 'audio/mp4',
            '.flac': 'audio/flac',
            '.ogg': 'audio/ogg',
            '.html': 'text/html',
            '.htm': 'text/html',
            '.xml': 'application/xml',
            '.json': 'application/json',
            '.csv': 'text/csv',
            '.txt': 'text/plain',
            '.md': 'text/markdown',
            '.rtf': 'application/rtf',
            '.epub': 'application/epub+zip',
            '.zip': 'application/zip',
            '.tar': 'application/x-tar',
            '.gz': 'application/gzip',
            '.7z': 'application/x-7z-compressed',
            '.rar': 'application/x-rar-compressed',
            '.msg': 'application/vnd.ms-outlook',
            '.eml': 'message/rfc822',
            '.ipynb': 'application/x-ipynb+json'
        }
        
        # MIME 타입-확장자 매핑 (역방향)
        self.mimetype_mapping = {v: k for k, v in self.extension_mapping.items()}
    
    def detect_from_stream(self, stream: BinaryIO) -> Optional[StreamInfo]:
        """스트림에서 파일 타입 감지"""
        if not self.magic_available:
            return None
        
        try:
            # 현재 위치 저장
            current_pos = stream.tell()
            
            # 파일 시작 부분 읽기
            stream.seek(0)
            header = stream.read(8192)  # 8KB 읽기
            
            # 원래 위치로 복원
            stream.seek(current_pos)
            
            if not header:
                return None
            
            # MIME 타입 감지
            mimetype = self.magic.from_buffer(header)
            
            # 확장자 추론
            extension = self.mimetype_mapping.get(mimetype)
            
            return StreamInfo(
                mimetype=mimetype,
                extension=extension
            )
            
        except Exception as e:
            logger.debug(f"Stream detection failed: {e}")
            return None
    
    def detect_from_filename(self, filename: str) -> Optional[StreamInfo]:
        """파일명에서 타입 감지"""
        path = Path(filename)
        extension = path.suffix.lower()
        
        if extension in self.extension_mapping:
            mimetype = self.extension_mapping[extension]
            return StreamInfo(
                mimetype=mimetype,
                extension=extension,
                filename=filename
            )
        
        return None
    
    def detect_from_extension(self, extension: str) -> Optional[StreamInfo]:
        """확장자에서 타입 감지"""
        if not extension.startswith('.'):
            extension = '.' + extension
        
        extension = extension.lower()
        
        if extension in self.extension_mapping:
            mimetype = self.extension_mapping[extension]
            return StreamInfo(
                mimetype=mimetype,
                extension=extension
            )
        
        return None
    
    def detect_from_mimetype(self, mimetype: str) -> Optional[StreamInfo]:
        """MIME 타입에서 정보 생성"""
        # 정확한 매칭 시도
        extension = self.mimetype_mapping.get(mimetype)
        if extension:
            return StreamInfo(
                mimetype=mimetype,
                extension=extension
            )
        
        # 부분 매칭 시도
        for mime, ext in self.mimetype_mapping.items():
            if mimetype.startswith(mime.split('/')[0]):
                return StreamInfo(
                    mimetype=mimetype,
                    extension=ext
                )
        
        return StreamInfo(mimetype=mimetype)
    
    def get_supported_extensions(self) -> List[str]:
        """지원하는 확장자 목록"""
        return list(self.extension_mapping.keys())
    
    def get_supported_mimetypes(self) -> List[str]:
        """지원하는 MIME 타입 목록"""
        return list(self.extension_mapping.values())
```

### 1.2 스트림 유틸리티
```python
# src/markitdown_mcp_enhanced/utils/stream_utils.py
import io
import shutil
from typing import BinaryIO, Optional
from ..config.logging_config import setup_logging

logger = setup_logging()

def make_stream_seekable(stream: BinaryIO, max_size: int = 100 * 1024 * 1024) -> BinaryIO:
    """스트림을 seekable하게 만들기"""
    if stream.seekable():
        return stream
    
    # 메모리 버퍼로 복사
    buffer = io.BytesIO()
    
    try:
        # 최대 크기 제한하여 복사
        copied = 0
        while copied < max_size:
            chunk = stream.read(min(8192, max_size - copied))
            if not chunk:
                break
            buffer.write(chunk)
            copied += len(chunk)
        
        if copied >= max_size:
            logger.warning(f"Stream truncated at {max_size} bytes")
        
        buffer.seek(0)
        return buffer
        
    except Exception as e:
        logger.error(f"Failed to make stream seekable: {e}")
        raise

def read_stream_with_encoding(stream: BinaryIO, 
                            encoding: Optional[str] = None,
                            fallback_encodings: Optional[list] = None) -> str:
    """스트림을 문자열로 읽기 (인코딩 자동 감지)"""
    if fallback_encodings is None:
        fallback_encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
    
    # 스트림 내용 읽기
    current_pos = stream.tell()
    stream.seek(0)
    content = stream.read()
    stream.seek(current_pos)
    
    # 지정된 인코딩으로 시도
    if encoding:
        try:
            return content.decode(encoding)
        except UnicodeDecodeError:
            logger.warning(f"Specified encoding {encoding} failed")
    
    # 인코딩 자동 감지
    try:
        import chardet
        detected = chardet.detect(content)
        if detected['encoding'] and detected['confidence'] > 0.8:
            return content.decode(detected['encoding'])
    except ImportError:
        pass
    
    # 대체 인코딩들 시도
    for enc in fallback_encodings:
        try:
            return content.decode(enc)
        except UnicodeDecodeError:
            continue
    
    # 모든 시도 실패시 오류 무시하고 디코딩
    return content.decode('utf-8', errors='ignore')

def get_stream_info(stream: BinaryIO) -> dict:
    """스트림 정보 수집"""
    info = {
        'readable': stream.readable(),
        'writable': stream.writable(),
        'seekable': stream.seekable(),
        'closed': stream.closed,
        'size': None,
        'position': None
    }
    
    try:
        if stream.seekable():
            current_pos = stream.tell()
            stream.seek(0, 2)  # 끝으로 이동
            info['size'] = stream.tell()
            stream.seek(current_pos)  # 원래 위치로 복원
            info['position'] = current_pos
    except Exception as e:
        logger.debug(f"Failed to get stream info: {e}")
    
    return info
```

### 1.3 포맷 유틸리티
```python
# src/markitdown_mcp_enhanced/utils/format_utils.py
import re
import html
from typing import Optional, Dict, Any
from ..config.logging_config import setup_logging

logger = setup_logging()

def clean_html(html_content: str) -> str:
    """HTML 정리"""
    # HTML 엔티티 디코딩
    html_content = html.unescape(html_content)
    
    # 스크립트와 스타일 태그 제거
    html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    
    # 불필요한 HTML 태그 제거
    html_content = re.sub(r'<[^>]+>', '', html_content)
    
    # 연속된 공백 정리
    html_content = re.sub(r'\s+', ' ', html_content)
    
    return html_content.strip()

def normalize_whitespace(text: str) -> str:
    """공백 정규화"""
    # 연속된 공백을 하나로
    text = re.sub(r'[ \t]+', ' ', text)
    
    # 연속된 줄바꿈을 최대 2개로
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    
    # 시작과 끝 공백 제거
    text = text.strip()
    
    return text

def extract_title_from_content(content: str, max_length: int = 100) -> Optional[str]:
    """내용에서 제목 추출"""
    lines = content.split('\n')
    
    for line in lines:
        line = line.strip()
        if line and len(line) <= max_length:
            # 헤딩 마크다운 제거
            line = re.sub(r'^#+\s*', '', line)
            
            # 특수 문자 제거
            line = re.sub(r'[^\w\s가-힣]', '', line)
            
            if line:
                return line
    
    return None

def format_metadata_table(metadata: Dict[str, Any]) -> str:
    """메타데이터를 테이블 형식으로 포맷"""
    if not metadata:
        return ""
    
    table = "| 항목 | 값 |\n|------|-----|\n"
    
    for key, value in metadata.items():
        # 키 한글화
        key_korean = {
            'filename': '파일명',
            'file_size': '파일 크기',
            'mimetype': 'MIME 타입',
            'author': '작성자',
            'title': '제목',
            'subject': '주제',
            'creation_date': '생성일',
            'modification_date': '수정일',
            'language': '언어',
            'page_count': '페이지 수',
            'word_count': '단어 수'
        }.get(key, key)
        
        # 값 포맷팅
        if isinstance(value, (int, float)):
            if key == 'file_size':
                value = format_file_size(value)
            elif key in ['creation_date', 'modification_date']:
                value = format_timestamp(value)
        
        table += f"| {key_korean} | {value} |\n"
    
    return table

def format_file_size(size: int) -> str:
    """파일 크기 포맷팅"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.1f} {unit}"
        size /= 1024.0
    return f"{size:.1f} TB"

def format_timestamp(timestamp: float) -> str:
    """타임스탬프 포맷팅"""
    import datetime
    try:
        dt = datetime.datetime.fromtimestamp(timestamp)
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    except:
        return str(timestamp)

def sanitize_filename(filename: str) -> str:
    """파일명 안전화"""
    # 안전하지 않은 문자 제거
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # 연속된 언더스코어 제거
    filename = re.sub(r'_+', '_', filename)
    
    # 시작과 끝 언더스코어 제거
    filename = filename.strip('_')
    
    return filename

def is_korean_text(text: str) -> bool:
    """한국어 텍스트 여부 확인"""
    korean_chars = len(re.findall(r'[가-힣]', text))
    total_chars = len(re.findall(r'[가-힣a-zA-Z]', text))
    
    if total_chars == 0:
        return False
    
    return (korean_chars / total_chars) > 0.3

def normalize_korean_spacing(text: str) -> str:
    """한국어 띄어쓰기 정규화"""
    # 조사 앞 공백 제거
    particles = ['은', '는', '이', '가', '을', '를', '에', '에서', '으로', '로', '와', '과', '의', '도', '만', '까지', '부터', '마저', '조차']
    
    for particle in particles:
        text = re.sub(rf'\s+{particle}\b', particle, text)
    
    # 문장 부호 앞 공백 제거
    text = re.sub(r'\s+([.!?,:;])', r'\1', text)
    
    # 괄호 안쪽 공백 정리
    text = re.sub(r'\(\s+', '(', text)
    text = re.sub(r'\s+\)', ')', text)
    
    return text

def escape_markdown_special_chars(text: str) -> str:
    """마크다운 특수 문자 이스케이프"""
    special_chars = ['\\', '`', '*', '_', '{', '}', '[', ']', '(', ')', '#', '+', '-', '.', '!', '|']
    
    for char in special_chars:
        text = text.replace(char, '\\' + char)
    
    return text

def create_markdown_table(headers: list, rows: list) -> str:
    """마크다운 테이블 생성"""
    if not headers or not rows:
        return ""
    
    # 헤더 행
    table = "| " + " | ".join(headers) + " |\n"
    
    # 구분선
    table += "| " + " | ".join(["---"] * len(headers)) + " |\n"
    
    # 데이터 행
    for row in rows:
        # 헤더 수에 맞게 행 길이 조정
        row_data = list(row)[:len(headers)]
        row_data.extend([""] * (len(headers) - len(row_data)))
        
        table += "| " + " | ".join(str(cell) for cell in row_data) + " |\n"
    
    return table

def extract_text_from_markdown(markdown: str) -> str:
    """마크다운에서 순수 텍스트 추출"""
    # 코드 블록 제거
    markdown = re.sub(r'```[^`]*```', '', markdown, flags=re.DOTALL)
    
    # 인라인 코드 제거
    markdown = re.sub(r'`[^`]*`', '', markdown)
    
    # 링크 제거 (텍스트만 남김)
    markdown = re.sub(r'\[([^\]]*)\]\([^\)]*\)', r'\1', markdown)
    
    # 이미지 제거
    markdown = re.sub(r'!\[([^\]]*)\]\([^\)]*\)', r'\1', markdown)
    
    # 헤딩 마크다운 제거
    markdown = re.sub(r'^#+\s*', '', markdown, flags=re.MULTILINE)
    
    # 볼드, 이탤릭 제거
    markdown = re.sub(r'\*\*([^\*]*)\*\*', r'\1', markdown)
    markdown = re.sub(r'\*([^\*]*)\*', r'\1', markdown)
    markdown = re.sub(r'__([^_]*)__', r'\1', markdown)
    markdown = re.sub(r'_([^_]*)_', r'\1', markdown)
    
    # 리스트 마커 제거
    markdown = re.sub(r'^\s*[*+-]\s*', '', markdown, flags=re.MULTILINE)
    markdown = re.sub(r'^\s*\d+\.\s*', '', markdown, flags=re.MULTILINE)
    
    # 인용문 제거
    markdown = re.sub(r'^\s*>\s*', '', markdown, flags=re.MULTILINE)
    
    # 공백 정규화
    markdown = normalize_whitespace(markdown)
    
    return markdown
```

## 2. 주요 변환기 구현

### 2.1 PDF 변환기
```python
# src/markitdown_mcp_enhanced/converters/pdf_converter.py
import io
from typing import BinaryIO, Optional, Dict, Any
import logging

from ..core.base_converter import DocumentConverter, DocumentConverterResult
from ..core.stream_info import StreamInfo
from ..core.exceptions import MissingDependencyException, FileConversionException
from ..utils.format_utils import normalize_whitespace, format_metadata_table

logger = logging.getLogger(__name__)

class PdfConverter(DocumentConverter):
    """PDF 파일 변환기"""
    
    supported_extensions = ['.pdf']
    supported_mimetypes = ['application/pdf']
    category = 'documents'
    
    def __init__(self, docintel_endpoint: Optional[str] = None, 
                 docintel_key: Optional[str] = None, 
                 korean_support: bool = True):
        super().__init__(korean_support=korean_support)
        self.docintel_endpoint = docintel_endpoint
        self.docintel_key = docintel_key
        self.priority = 0.0
        
        # 의존성 확인
        self._check_dependencies()
    
    def _check_dependencies(self):
        """의존성 확인"""
        try:
            import pdfminer.six
            self.pdfminer_available = True
        except ImportError:
            self.pdfminer_available = False
        
        try:
            from azure.ai.documentintelligence import DocumentIntelligenceClient
            self.azure_available = bool(self.docintel_endpoint and self.docintel_key)
        except ImportError:
            self.azure_available = False
    
    def accepts(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> bool:
        """PDF 파일 처리 가능 여부"""
        return (stream_info.matches_mimetype(['application/pdf']) or 
                stream_info.matches_extension(['.pdf']))
    
    def convert(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """PDF 변환 수행"""
        logger.info(f"Converting PDF: {stream_info.filename}")
        
        # Azure Document Intelligence 우선 사용
        if self.azure_available:
            try:
                return self._convert_with_azure(file_stream, stream_info, **kwargs)
            except Exception as e:
                logger.warning(f"Azure Document Intelligence failed: {e}")
        
        # pdfminer 사용
        if self.pdfminer_available:
            return self._convert_with_pdfminer(file_stream, stream_info, **kwargs)
        
        raise MissingDependencyException(
            "No PDF processing library available. Install pdfminer.six or configure Azure Document Intelligence"
        )
    
    def _convert_with_azure(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """Azure Document Intelligence로 변환"""
        from azure.ai.documentintelligence import DocumentIntelligenceClient
        from azure.core.credentials import AzureKeyCredential
        
        try:
            # 클라이언트 생성
            client = DocumentIntelligenceClient(
                endpoint=self.docintel_endpoint,
                credential=AzureKeyCredential(self.docintel_key)
            )
            
            # 문서 분석
            file_stream.seek(0)
            poller = client.begin_analyze_document(
                "prebuilt-layout",
                file_stream,
                content_type="application/pdf"
            )
            
            result = poller.result()
            
            # 마크다운 변환
            markdown = self._azure_result_to_markdown(result)
            
            # 메타데이터 추출
            metadata = self._extract_azure_metadata(result, stream_info)
            
            # 제목 추출
            title = self._extract_title_from_azure_result(result)
            
            return DocumentConverterResult(
                markdown=self._clean_markdown(markdown),
                title=title,
                metadata=metadata
            )
            
        except Exception as e:
            raise FileConversionException(f"Azure Document Intelligence conversion failed: {e}")
    
    def _convert_with_pdfminer(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """pdfminer로 변환"""
        from pdfminer.high_level import extract_text
        from pdfminer.layout import LAParams
        from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
        from pdfminer.pdfpage import PDFPage
        from pdfminer.converter import PDFPageAggregator
        from pdfminer.layout import LTTextContainer, LTTextBox, LTTextLine
        
        try:
            file_stream.seek(0)
            
            # 기본 텍스트 추출
            text = extract_text(file_stream)
            
            # 구조화된 변환 시도
            file_stream.seek(0)
            structured_content = self._extract_structured_content(file_stream)
            
            # 마크다운 변환
            if structured_content:
                markdown = self._structured_content_to_markdown(structured_content)
            else:
                markdown = self._text_to_markdown(text)
            
            # 메타데이터 추출
            metadata = self._extract_pdf_metadata(file_stream, stream_info)
            
            # 제목 추출
            title = self._extract_title_from_text(text)
            
            return DocumentConverterResult(
                markdown=self._clean_markdown(markdown),
                title=title,
                metadata=metadata
            )
            
        except Exception as e:
            raise FileConversionException(f"PDF conversion failed: {e}")
    
    def _extract_structured_content(self, file_stream: BinaryIO) -> Optional[list]:
        """구조화된 내용 추출"""
        from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
        from pdfminer.pdfpage import PDFPage
        from pdfminer.converter import PDFPageAggregator
        from pdfminer.layout import LAParams, LTTextContainer, LTTextBox, LTTextLine
        
        try:
            resource_manager = PDFResourceManager()
            laparams = LAParams(
                word_margin=0.1,
                line_margin=0.5,
                char_margin=2.0,
                boxes_flow=0.5
            )
            
            device = PDFPageAggregator(resource_manager, laparams=laparams)
            interpreter = PDFPageInterpreter(resource_manager, device)
            
            pages = []
            for page in PDFPage.get_pages(file_stream):
                interpreter.process_page(page)
                layout = device.get_result()
                
                page_content = []
                for element in layout:
                    if isinstance(element, LTTextContainer):
                        text = element.get_text().strip()
                        if text:
                            page_content.append({
                                'text': text,
                                'bbox': element.bbox,
                                'font_size': getattr(element, 'fontsize', None)
                            })
                
                if page_content:
                    pages.append(page_content)
            
            return pages
            
        except Exception as e:
            logger.debug(f"Structured content extraction failed: {e}")
            return None
    
    def _azure_result_to_markdown(self, result) -> str:
        """Azure 결과를 마크다운으로 변환"""
        markdown = ""
        
        if hasattr(result, 'paragraphs') and result.paragraphs:
            for paragraph in result.paragraphs:
                content = paragraph.content.strip()
                if content:
                    # 헤딩 감지
                    if self._is_heading(content):
                        level = self._get_heading_level(content)
                        markdown += f"{'#' * level} {content}\n\n"
                    else:
                        markdown += f"{content}\n\n"
        
        # 테이블 처리
        if hasattr(result, 'tables') and result.tables:
            for table in result.tables:
                markdown += self._azure_table_to_markdown(table)
                markdown += "\n\n"
        
        return markdown
    
    def _azure_table_to_markdown(self, table) -> str:
        """Azure 테이블을 마크다운으로 변환"""
        if not hasattr(table, 'cells') or not table.cells:
            return ""
        
        # 테이블 구조 분석
        max_row = max(cell.row_index for cell in table.cells) + 1
        max_col = max(cell.column_index for cell in table.cells) + 1
        
        # 테이블 생성
        table_data = [[""] * max_col for _ in range(max_row)]
        
        for cell in table.cells:
            content = cell.content.strip() if cell.content else ""
            table_data[cell.row_index][cell.column_index] = content
        
        # 마크다운 테이블 생성
        if not table_data:
            return ""
        
        markdown = "| " + " | ".join(table_data[0]) + " |\n"
        markdown += "| " + " | ".join(["---"] * max_col) + " |\n"
        
        for row in table_data[1:]:
            markdown += "| " + " | ".join(row) + " |\n"
        
        return markdown
    
    def _structured_content_to_markdown(self, pages: list) -> str:
        """구조화된 내용을 마크다운으로 변환"""
        markdown = ""
        
        for page_idx, page in enumerate(pages):
            if page_idx > 0:
                markdown += "\n---\n\n"  # 페이지 구분
            
            for element in page:
                text = element['text'].strip()
                if not text:
                    continue
                
                # 헤딩 감지
                if self._is_heading(text):
                    level = self._get_heading_level(text)
                    markdown += f"{'#' * level} {text}\n\n"
                else:
                    markdown += f"{text}\n\n"
        
        return markdown
    
    def _text_to_markdown(self, text: str) -> str:
        """일반 텍스트를 마크다운으로 변환"""
        if not text:
            return ""
        
        # 텍스트 정규화
        text = normalize_whitespace(text)
        
        # 단락 분리
        paragraphs = text.split('\n\n')
        
        markdown = ""
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            # 헤딩 감지
            if self._is_heading(paragraph):
                level = self._get_heading_level(paragraph)
                markdown += f"{'#' * level} {paragraph}\n\n"
            else:
                markdown += f"{paragraph}\n\n"
        
        return markdown
    
    def _is_heading(self, text: str) -> bool:
        """헤딩 여부 판단"""
        text = text.strip()
        
        # 길이 기준 (너무 긴 텍스트는 헤딩이 아님)
        if len(text) > 100:
            return False
        
        # 마침표로 끝나지 않는 짧은 텍스트
        if len(text) < 100 and not text.endswith('.'):
            return True
        
        # 숫자로 시작하는 제목 (1. 서론, 1.1 개요 등)
        if text.startswith(tuple('0123456789')):
            return True
        
        return False
    
    def _get_heading_level(self, text: str) -> int:
        """헤딩 레벨 결정"""
        text = text.strip()
        
        # 숫자 기반 레벨 (1. -> 1, 1.1 -> 2, 1.1.1 -> 3)
        if text.startswith(tuple('0123456789')):
            dots = text.split()[0].count('.')
            return min(dots + 1, 6)
        
        # 기본 레벨
        return 2
    
    def _extract_pdf_metadata(self, file_stream: BinaryIO, stream_info: StreamInfo) -> Dict[str, Any]:
        """PDF 메타데이터 추출"""
        metadata = self._extract_metadata(file_stream, stream_info)
        
        try:
            from pdfminer.pdfparser import PDFParser
            from pdfminer.pdfdocument import PDFDocument
            
            file_stream.seek(0)
            parser = PDFParser(file_stream)
            document = PDFDocument(parser)
            
            if document.info:
                for info in document.info:
                    for key, value in info.items():
                        if isinstance(value, bytes):
                            try:
                                value = value.decode('utf-8')
                            except UnicodeDecodeError:
                                value = value.decode('latin-1')
                        metadata[key.lower()] = value
            
        except Exception as e:
            logger.debug(f"PDF metadata extraction failed: {e}")
        
        return metadata
    
    def _extract_azure_metadata(self, result, stream_info: StreamInfo) -> Dict[str, Any]:
        """Azure 결과에서 메타데이터 추출"""
        metadata = self._extract_metadata(None, stream_info)
        
        if hasattr(result, 'pages') and result.pages:
            metadata['page_count'] = len(result.pages)
        
        if hasattr(result, 'paragraphs') and result.paragraphs:
            word_count = sum(len(p.content.split()) for p in result.paragraphs if p.content)
            metadata['word_count'] = word_count
        
        return metadata
    
    def _extract_title_from_azure_result(self, result) -> Optional[str]:
        """Azure 결과에서 제목 추출"""
        if hasattr(result, 'paragraphs') and result.paragraphs:
            for paragraph in result.paragraphs:
                if paragraph.content:
                    text = paragraph.content.strip()
                    if text and len(text) < 100:
                        return self._format_title(text)
        return None
    
    def _extract_title_from_text(self, text: str) -> Optional[str]:
        """텍스트에서 제목 추출"""
        if not text:
            return None
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if line and len(line) < 100:
                return self._format_title(line)
        
        return None
```

### 2.2 DOCX 변환기
```python
# src/markitdown_mcp_enhanced/converters/docx_converter.py
from typing import BinaryIO, Dict, Any, Optional
import logging

from ..core.base_converter import DocumentConverter, DocumentConverterResult
from ..core.stream_info import StreamInfo
from ..core.exceptions import MissingDependencyException, FileConversionException
from ..utils.format_utils import normalize_whitespace

logger = logging.getLogger(__name__)

class DocxConverter(DocumentConverter):
    """DOCX 파일 변환기"""
    
    supported_extensions = ['.docx']
    supported_mimetypes = ['application/vnd.openxmlformats-officedocument.wordprocessingml.document']
    category = 'documents'
    
    def __init__(self, korean_support: bool = True):
        super().__init__(korean_support=korean_support)
        self.priority = 0.1
        
        # 의존성 확인
        self._check_dependencies()
    
    def _check_dependencies(self):
        """의존성 확인"""
        try:
            import mammoth
            self.mammoth_available = True
        except ImportError:
            self.mammoth_available = False
        
        try:
            from docx import Document
            self.python_docx_available = True
        except ImportError:
            self.python_docx_available = False
    
    def accepts(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> bool:
        """DOCX 파일 처리 가능 여부"""
        return (stream_info.matches_mimetype(['application/vnd.openxmlformats-officedocument.wordprocessingml.document']) or
                stream_info.matches_extension(['.docx']))
    
    def convert(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """DOCX 변환 수행"""
        logger.info(f"Converting DOCX: {stream_info.filename}")
        
        # mammoth 우선 사용 (더 좋은 변환 품질)
        if self.mammoth_available:
            try:
                return self._convert_with_mammoth(file_stream, stream_info, **kwargs)
            except Exception as e:
                logger.warning(f"Mammoth conversion failed: {e}")
        
        # python-docx 사용
        if self.python_docx_available:
            return self._convert_with_python_docx(file_stream, stream_info, **kwargs)
        
        raise MissingDependencyException(
            "No DOCX processing library available. Install mammoth or python-docx"
        )
    
    def _convert_with_mammoth(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """mammoth로 변환"""
        import mammoth
        
        try:
            file_stream.seek(0)
            
            # 스타일 맵 설정
            style_map = self._get_style_map()
            
            # HTML로 변환
            result = mammoth.convert_to_html(file_stream, style_map=style_map)
            html_content = result.value
            
            # 경고 메시지 처리
            if result.messages:
                logger.debug(f"Mammoth warnings: {result.messages}")
            
            # HTML을 마크다운으로 변환
            markdown = self._html_to_markdown(html_content)
            
            # 메타데이터 추출
            metadata = self._extract_docx_metadata(file_stream, stream_info)
            
            # 제목 추출
            title = self._extract_title_from_markdown(markdown)
            
            return DocumentConverterResult(
                markdown=self._clean_markdown(markdown),
                title=title,
                metadata=metadata
            )
            
        except Exception as e:
            raise FileConversionException(f"Mammoth conversion failed: {e}")
    
    def _convert_with_python_docx(self, file_stream: BinaryIO, stream_info: StreamInfo, **kwargs) -> DocumentConverterResult:
        """python-docx로 변환"""
        from docx import Document
        
        try:
            file_stream.seek(0)
            doc = Document(file_stream)
            
            # 마크다운 변환
            markdown = self._docx_to_markdown(doc)
            
            # 메타데이터 추출
            metadata = self._extract_docx_metadata_from_doc(doc, stream_info)
            
            # 제목 추출
            title = self._extract_title_from_doc(doc)
            
            return DocumentConverterResult(
                markdown=self._clean_markdown(markdown),
                title=title,
                metadata=metadata
            )
            
        except Exception as e:
            raise FileConversionException(f"python-docx conversion failed: {e}")
    
    def _get_style_map(self) -> str:
        """mammoth 스타일 맵 설정"""
        return """
            p[style-name='Heading 1'] => h1
            p[style-name='Heading 2'] => h2
            p[style-name='Heading 3'] => h3
            p[style-name='Heading 4'] => h4
            p[style-name='Heading 5'] => h5
            p[style-name='Heading 6'] => h6
            p[style-name='제목 1'] => h1
            p[style-name='제목 2'] => h2
            p[style-name='제목 3'] => h3
            p[style-name='제목 4'] => h4
            p[style-name='제목 5'] => h5
            p[style-name='제목 6'] => h6
            p[style-name='Title'] => h1
            p[style-name='Subtitle'] => h2
            table => table
            tr => tr
            td => td
            th => th
            ul => ul
            ol => ol
            li => li
            p => p
            br => br
            strong => strong
            em => em
        """
    
    def _html_to_markdown(self, html_content: str) -> str:
        """HTML을 마크다운으로 변환"""
        try:
            import markdownify
            
            # markdownify 설정
            markdown = markdownify.markdownify(
                html_content,
                heading_style="ATX",
                bullets="-",
                strip=['script', 'style'],
                convert=['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 
                        'strong', 'em', 'ul', 'ol', 'li', 'a', 'img', 
                        'table', 'thead', 'tbody', 'tr', 'th', 'td', 'br']
            )
            
            return markdown
            
        except ImportError:
            # markdownify가 없으면 기본 변환
            return self._basic_html_to_markdown(html_content)
    
    def _basic_html_to_markdown(self, html_content: str) -> str:
        """기본 HTML-마크다운 변환"""
        from bs4 import BeautifulSoup
        import re
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # 헤딩 변환
        for level in range(1, 7):
            for heading in soup.find_all(f'h{level}'):
                heading.string = f"{'#' * level} {heading.get_text()}\n\n"
        
        # 강조 변환
        for strong in soup.find_all('strong'):
            strong.string = f"**{strong.get_text()}**"
        
        for em in soup.find_all('em'):
            em.string = f"*{em.get_text()}*"
        
        # 리스트 변환
        for ul in soup.find_all('ul'):
            items = ul.find_all('li')
            list_text = '\n'.join(f"- {item.get_text()}" for item in items)
            ul.string = f"{list_text}\n\n"
        
        # 텍스트 추출
        text = soup.get_text()
        
        # 정리
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = text.strip()
        
        return text
    
    def _docx_to_markdown(self, doc) -> str:
        """python-docx Document를 마크다운으로 변환"""
        markdown = ""
        
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if not text:
                continue
            
            # 스타일 기반 변환
            style_name = paragraph.style.name if paragraph.style else ""
            
            if 'Heading' in style_name or '제목' in style_name:
                # 헤딩 처리
                level = self._extract_heading_level(style_name)
                markdown += f"{'#' * level} {text}\n\n"
            else:
                # 일반 단락
                markdown += f"{text}\n\n"
        
        # 테이블 처리
        for table in doc.tables:
            markdown += self._table_to_markdown(table)
            markdown += "\n\n"
        
        return markdown
    
    def _extract_heading_level(self, style_name: str) -> int:
        """스타일명에서 헤딩 레벨 추출"""
        import re
        
        # 숫자 추출
        match = re.search(r'(\d+)', style_name)
        if match:
            level = int(match.group(1))
            return min(level, 6)
        
        return 1
    
    def _table_to_markdown(self, table) -> str:
        """테이블을 마크다운으로 변환"""
        if not table.rows:
            return ""
        
        markdown = ""
        
        # 헤더 행
        header_cells = [cell.text.strip() for cell in table.rows[0].cells]
        markdown += "| " + " | ".join(header_cells) + " |\n"
        markdown += "| " + " | ".join(["---"] * len(header_cells)) + " |\n"
        
        # 데이터 행
        for row in table.rows[1:]:
            cells = [cell.text.strip() for cell in row.cells]
            # 헤더 수에 맞게 셀 수 조정
            cells = cells[:len(header_cells)]
            cells.extend([""] * (len(header_cells) - len(cells)))
            
            markdown += "| " + " | ".join(cells) + " |\n"
        
        return markdown
    
    def _extract_docx_metadata(self, file_stream: BinaryIO, stream_info: StreamInfo) -> Dict[str, Any]:
        """DOCX 메타데이터 추출 (mammoth 사용시)"""
        metadata = self._extract_metadata(file_stream, stream_info)
        
        try:
            from docx import Document
            file_stream.seek(0)
            doc = Document(file_stream)
            
            # 문서 속성 추출
            core_props = doc.core_properties
            
            if core_props.title:
                metadata['title'] = core_props.title
            if core_props.author:
                metadata['author'] = core_props.author
            if core_props.subject:
                metadata['subject'] = core_props.subject
            if core_props.created:
                metadata['creation_date'] = core_props.created.isoformat()
            if core_props.modified:
                metadata['modification_date'] = core_props.modified.isoformat()
            
            # 통계 정보
            word_count = sum(len(p.text.split()) for p in doc.paragraphs if p.text.strip())
            metadata['word_count'] = word_count
            metadata['paragraph_count'] = len(doc.paragraphs)
            
        except Exception as e:
            logger.debug(f"DOCX metadata extraction failed: {e}")
        
        return metadata
    
    def _extract_docx_metadata_from_doc(self, doc, stream_info: StreamInfo) -> Dict[str, Any]:
        """Document 객체에서 메타데이터 추출"""
        metadata = self._extract_metadata(None, stream_info)
        
        try:
            # 문서 속성 추출
            core_props = doc.core_properties
            
            if core_props.title:
                metadata['title'] = core_props.title
            if core_props.author:
                metadata['author'] = core_props.author
            if core_props.subject:
                metadata['subject'] = core_props.subject
            if core_props.created:
                metadata['creation_date'] = core_props.created.isoformat()
            if core_props.modified:
                metadata['modification_date'] = core_props.modified.isoformat()
            
            # 통계 정보
            word_count = sum(len(p.text.split()) for p in doc.paragraphs if p.text.strip())
            metadata['word_count'] = word_count
            metadata['paragraph_count'] = len(doc.paragraphs)
            
        except Exception as e:
            logger.debug(f"DOCX metadata extraction failed: {e}")
        
        return metadata
    
    def _extract_title_from_markdown(self, markdown: str) -> Optional[str]:
        """마크다운에서 제목 추출"""
        import re
        
        # 첫 번째 헤딩 찾기
        match = re.search(r'^#\s+(.+)$', markdown, re.MULTILINE)
        if match:
            return self._format_title(match.group(1))
        
        return None
    
    def _extract_title_from_doc(self, doc) -> Optional[str]:
        """Document 객체에서 제목 추출"""
        # 문서 속성에서 제목 추출
        if doc.core_properties.title:
            return self._format_title(doc.core_properties.title)
        
        # 첫 번째 헤딩 스타일 단락에서 제목 추출
        for paragraph in doc.paragraphs:
            if paragraph.style and ('Heading' in paragraph.style.name or '제목' in paragraph.style.name):
                text = paragraph.text.strip()
                if text:
                    return self._format_title(text)
        
        # 첫 번째 단락에서 제목 추출
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if text and len(text) < 100:
                return self._format_title(text)
        
        return None
```

이제 나머지 변환기들과 유틸리티 모듈들을 계속 구현하겠습니다.

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "MCP \uc11c\ubc84 \uad6c\ucd95 \ud3f4\ub354 \ubc0f \ud558\uc704\uad6c\uc870 \uc0dd\uc131", "status": "completed", "priority": "high", "id": "30"}, {"content": "markitdown GitHub \ub9ac\ud3ec\uc9c0\ud1a0\ub9ac \ubd84\uc11d", "status": "completed", "priority": "high", "id": "31"}, {"content": "markitdown MCP \uc11c\ubc84 \uae30\ub2a5 \ubca4\uce58\ub9c8\ud0b9", "status": "completed", "priority": "high", "id": "32"}, {"content": "\ub3d9\uc77c \uae30\ub2a5 MCP \uc11c\ubc84 \uad6c\ud604", "status": "completed", "priority": "high", "id": "33"}, {"content": "\uc5c5\uadf8\ub808\uc774\ub4dc \ubc84\uc804 \uae30\ub2a5 \uc124\uacc4", "status": "pending", "priority": "medium", "id": "34"}, {"content": "\ud578\uc2ec \ubcc0\ud658 \uc5d4\uc9c4 \uad6c\ud604", "status": "completed", "priority": "high", "id": "35"}, {"content": "\uae30\ubcf8 \ubcc0\ud658\uae30 \uc2dc\uc2a4\ud15c \uad6c\ud604", "status": "completed", "priority": "high", "id": "36"}, {"content": "\ud50c\ub7ec\uadf8\uc778 \uc2dc\uc2a4\ud15c \uad6c\ud604", "status": "pending", "priority": "medium", "id": "37"}, {"content": "PDF \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "38"}, {"content": "DOCX \ubcc0\ud658\uae30 \uad6c\ud604", "status": "completed", "priority": "high", "id": "39"}, {"content": "\uc774\ubbf8\uc9c0 \ubcc0\ud658\uae30 \uad6c\ud604", "status": "in_progress", "priority": "high", "id": "40"}, {"content": "\uc624\ub514\uc624 \ubcc0\ud658\uae30 \uad6c\ud604", "status": "pending", "priority": "high", "id": "41"}, {"content": "HTML \ubcc0\ud658\uae30 \uad6c\ud604", "status": "pending", "priority": "medium", "id": "42"}, {"content": "\uc720\ud2f8\ub9ac\ud2f0 \ubaa8\ub4c8 \uad6c\ud604", "status": "completed", "priority": "medium", "id": "43"}]